{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected multiples argument to be a vector of length 3 but got length 2 [Op:Tile]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6441eee0571c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m \u001b[0mtriplet_semihard_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6441eee0571c>\u001b[0m in \u001b[0;36mtriplet_semihard_loss\u001b[0;34m(y_true, y_pred, margin, distance_metric)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mdistance_matrix_tiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     mask = tf.math.logical_and(\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjacency_not\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         tf.math.greater(\n\u001b[1;32m    134\u001b[0m             \u001b[0mdistance_matrix_tiled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gl/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(input, multiples, name)\u001b[0m\n\u001b[1;32m  11391\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11392\u001b[0m       return tile_eager_fallback(\n\u001b[0;32m> 11393\u001b[0;31m           input, multiples, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m  11394\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11395\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gl/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtile_eager_fallback\u001b[0;34m(input, multiples, name, ctx)\u001b[0m\n\u001b[1;32m  11431\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tmultiples\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tmultiples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11432\u001b[0m   _result = _execute.execute(b\"Tile\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m> 11433\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m  11434\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11435\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m~/.virtualenvs/gl/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected multiples argument to be a vector of length 3 but got length 2 [Op:Tile]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def angular_distance(features):\n",
    "    features = tf.math.l2_normalize(features, axis=1)\n",
    "    angular_distances = 1 - tf.matmul(features, features, transpose_b=True)\n",
    "    return tf.maximum(angular_distances, 0.0)\n",
    "\n",
    "def pairwise_distances(features, squared=False):\n",
    "    dot_product = tf.matmul(features, tf.transpose(features))\n",
    "    square_norm = tf.linalg.diag_part(dot_product)\n",
    "    distances = tf.expand_dims(square_norm, 0) - 2.0 * dot_product + tf.expand_dims(square_norm, 1)\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "    if not squared:\n",
    "        mask = tf.cast(tf.equal(distances, 0.0), dtype=tf.float32)\n",
    "        distances = distances + mask * 1e-16\n",
    "        distances = tf.sqrt(distances)\n",
    "        distances = distances * (1.0 - mask)\n",
    "    return distances\n",
    "\n",
    "def _obtain_anchors_largest_distance_to_positive(data, mask, dim=1):\n",
    "    axis_minimums = tf.math.reduce_min(data, dim, keepdims=True)\n",
    "    masked_maximums = (\n",
    "        tf.math.reduce_max(\n",
    "            tf.math.multiply(data - axis_minimums, mask), dim, keepdims=True\n",
    "        )\n",
    "        + axis_minimums\n",
    "    )\n",
    "    return masked_maximums\n",
    "\n",
    "def _obtain_anchors_smallest_distance_to_negative(data, mask, dim=1):\n",
    "    axis_maximums = tf.math.reduce_max(data, dim, keepdims=True)\n",
    "    masked_minimums = (\n",
    "        tf.math.reduce_min(\n",
    "            tf.math.multiply(data - axis_maximums, mask), dim, keepdims=True\n",
    "        )\n",
    "        + axis_maximums\n",
    "    )\n",
    "    return masked_minimums\n",
    "\n",
    "def triplet_hard_loss(y_true, y_pred, margin=1.0, distance_metric='L2', soft=False):\n",
    "\n",
    "    labels, embeddings = y_true, y_pred\n",
    "\n",
    "    convert_to_float32 = (\n",
    "        embeddings.dtype == tf.dtypes.float16 or embeddings.dtype == tf.dtypes.bfloat16\n",
    "    )\n",
    "    precise_embeddings = (\n",
    "        tf.cast(embeddings, tf.dtypes.float32) if convert_to_float32 else embeddings\n",
    "    )\n",
    "\n",
    "    labels = tf.expand_dims(labels, -1)\n",
    "\n",
    "    if distance_metric == \"L1\":\n",
    "        distance_matrix = pairwise_distances(\n",
    "            precise_embeddings, squared=False\n",
    "        )\n",
    "\n",
    "    elif distance_metric == \"L2\":\n",
    "        distance_matrix = pairwise_distances(\n",
    "            precise_embeddings, squared=True\n",
    "        )\n",
    "\n",
    "    elif distance_metric == \"angular\":\n",
    "        distance_matrix = angular_distance(precise_embeddings)\n",
    "\n",
    "    adjacency = tf.math.equal(labels, tf.transpose(labels))\n",
    "    adjacency_not = tf.math.logical_not(adjacency)\n",
    "    adjacency_not = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n",
    "\n",
    "    # obtain the smallest Distance(A, N) for each feature\n",
    "    hard_negatives = _obtain_anchors_smallest_distance_to_negative(\n",
    "        distance_matrix, adjacency_not)\n",
    "\n",
    "    batch_size = tf.size(labels)\n",
    "\n",
    "    adjacency = tf.cast(adjacency, dtype=tf.dtypes.float32)\n",
    "    mask_positives = adjacency - tf.linalg.diag(tf.ones([batch_size]))\n",
    "\n",
    "    # obtain the largest Distance(A, P) for each feature\n",
    "    hard_positives = _obtain_anchors_largest_distance_to_positive(\n",
    "        distance_matrix, mask_positives)\n",
    "\n",
    "    if soft:\n",
    "        triplet_loss = tf.math.log1p(tf.math.exp(hard_positives - hard_negatives))\n",
    "    else:\n",
    "        triplet_loss = tf.maximum(hard_positives - hard_negatives + margin, 0.0)\n",
    "\n",
    "    triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "\n",
    "    if convert_to_float32:\n",
    "        return tf.cast(triplet_loss, embeddings.dtype)\n",
    "    else:\n",
    "        return triplet_loss\n",
    "\n",
    "def triplet_semihard_loss(y_true, y_pred, margin=1.0, distance_metric=\"L2\"):\n",
    "\n",
    "    labels, embeddings = y_true, y_pred\n",
    "\n",
    "    convert_to_float32 = (\n",
    "        embeddings.dtype == tf.dtypes.float16 or embeddings.dtype == tf.dtypes.bfloat16\n",
    "    )\n",
    "    precise_embeddings = (\n",
    "        tf.cast(embeddings, tf.dtypes.float32) if convert_to_float32 else embeddings\n",
    "    )\n",
    "\n",
    "    labels = tf.expand_dims(labels, -1)\n",
    "\n",
    "    if distance_metric == \"L1\":\n",
    "        distance_matrix = pairwise_distances(\n",
    "            precise_embeddings, squared=False\n",
    "        )\n",
    "    elif distance_metric == \"L2\":\n",
    "        distance_matrix = pairwise_distances(\n",
    "            precise_embeddings, squared=True\n",
    "        )\n",
    "    elif distance_metric == \"angular\":\n",
    "        distance_matrix = angular_distance(precise_embeddings)\n",
    "    else:\n",
    "        distance_matrix = distance_metric(precise_embeddings)\n",
    "\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = tf.math.equal(labels, tf.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = tf.math.logical_not(adjacency)\n",
    "\n",
    "    batch_size = tf.size(labels)\n",
    "\n",
    "    # Compute the mask.\n",
    "    distance_matrix_tiled = tf.tile(distance_matrix, [batch_size, 1])\n",
    "    mask = tf.math.logical_and(\n",
    "        tf.tile(adjacency_not, [batch_size, 1]),\n",
    "        tf.math.greater(\n",
    "            distance_matrix_tiled, tf.reshape(tf.transpose(distance_matrix), [-1, 1])\n",
    "        ),\n",
    "    )\n",
    "    mask_final = tf.reshape(\n",
    "        tf.math.greater(\n",
    "            tf.math.reduce_sum(\n",
    "                tf.cast(mask, dtype=tf.dtypes.float32), 1, keepdims=True\n",
    "            ),\n",
    "            0.0,\n",
    "        ),\n",
    "        [batch_size, batch_size],\n",
    "    )\n",
    "    mask_final = tf.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = tf.reshape(\n",
    "        _obtain_anchors_smallest_distance_to_negative(distance_matrix_tiled, mask), [batch_size, batch_size]\n",
    "    )\n",
    "    negatives_outside = tf.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = tf.tile(\n",
    "        _obtain_anchors_largest_distance_to_positive(distance_matrix, adjacency_not), [1, batch_size]\n",
    "    )\n",
    "    semi_hard_negatives = tf.where(mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "    loss_mat = tf.math.add(margin, distance_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = tf.cast(adjacency, dtype=tf.dtypes.float32) - tf.linalg.diag(\n",
    "        tf.ones([batch_size])\n",
    "    )\n",
    "\n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = tf.math.reduce_sum(mask_positives)\n",
    "\n",
    "    triplet_loss = tf.math.truediv(\n",
    "        tf.math.reduce_sum(\n",
    "            tf.math.maximum(tf.math.multiply(loss_mat, mask_positives), 0.0)\n",
    "        ),\n",
    "        num_positives,\n",
    "    )\n",
    "\n",
    "    if convert_to_float32:\n",
    "        return tf.cast(triplet_loss, embeddings.dtype)\n",
    "    else:\n",
    "        return triplet_loss\n",
    "\n",
    "embedding = tf.constant([\n",
    "    [1,2,3,4,5,6],\n",
    "    [4,2,1,6,7,8],\n",
    "    [4,5,6,3,2,1],\n",
    "    [1,3,3,4,7,8],\n",
    "    [4,4,6,3,2,1],\n",
    "    [1,6,6,6,7,8],\n",
    "    [4,1,6,6,2,1],\n",
    "    [1,1,3,6,7,8],\n",
    "    [4,1,4,6,2,1],\n",
    "    [1,9,7,2,7,8],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "y_true = tf.constant([[1,0,0,1,1,1,1,0,0,0]])\n",
    "y_pred = embedding\n",
    "\n",
    "triplet_semihard_loss(y_true, y_pred, distance_metric='L2')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=2.5212498>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.5>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_anchor_positive_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i and j are distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "\n",
    "    # Check if labels[i] == labels[j]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(indices_not_equal, labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_anchor_negative_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check if labels[i] != labels[k]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    mask = tf.logical_not(labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_triplet_mask(labels):\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "    A triplet (i, j, k) is valid if:\n",
    "        - i, j, k are distinct\n",
    "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i, j and k are distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(distinct_indices, valid_labels)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def batch_all_triplet_loss(labels, embeddings, margin=1.0, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    We generate all the valid triplets and average the loss over the positive ones.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\n",
    "    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1)\n",
    "\n",
    "    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\n",
    "    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "    # and the 2nd (batch_size, 1, batch_size)\n",
    "    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
    "\n",
    "    # Put to zero the invalid triplets\n",
    "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\n",
    "    mask = _get_triplet_mask(labels)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    triplet_loss = tf.multiply(mask, triplet_loss)\n",
    "\n",
    "    # Remove negative losses (i.e. the easy triplets)\n",
    "    triplet_loss = tf.maximum(triplet_loss, 0.0)\n",
    "\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    valid_triplets = tf.cast(tf.greater(triplet_loss, 1e-16), dtype=tf.float32)\n",
    "    num_positive_triplets = tf.reduce_sum(valid_triplets)\n",
    "    num_valid_triplets = tf.reduce_sum(mask)\n",
    "    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets + 1e-16)\n",
    "\n",
    "    # Get final mean triplet loss over the positive valid triplets\n",
    "    triplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + 1e-16)\n",
    "\n",
    "    return triplet_loss, fraction_positive_triplets\n",
    "\n",
    "batch_all_triplet_loss(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 ms ± 25 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def batch_hard_triplet_loss(labels, embeddings, margin=1.0, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    # For each anchor, get the hardest positive\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n",
    "    mask_anchor_positive = tf.cast(mask_anchor_positive, dtype=tf.float32)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n",
    "    mask_anchor_negative = tf.cast(mask_anchor_negative, dtype=tf.float32)\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "    # shape (batch_size,)\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
    "\n",
    "    # Get final mean triplet loss\n",
    "    triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "\n",
    "    return triplet_loss\n",
    "\n",
    "%timeit batch_hard_triplet_loss(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
